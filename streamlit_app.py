# kospi_research_app.py
import streamlit as st
import pandas as pd
import sqlite3
import requests
from io import StringIO
import gdown
import os
import zipfile
import tarfile
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
import torch

st.set_page_config(page_title="ğŸ“ˆ KOSPI Analyst AI", layout="wide")

# Google Drive íŒŒì¼ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜
@st.cache_resource
def download_and_load_models():
    """Google Driveì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ"""
    
    # Google Drive íŒŒì¼ ID (ê³µìœ  ë§í¬ì—ì„œ ì¶”ì¶œ)
    base_model_id = "YOUR_BASE_MODEL_FILE_ID"  # my_base_model.tar.gzì˜ íŒŒì¼ ID
    qlora_adapter_id = "YOUR_QLORA_ADAPTER_FILE_ID"  # qlora_results.zipì˜ íŒŒì¼ ID
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        # ë² ì´ìŠ¤ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
        status_text.text("ğŸ”„ ë² ì´ìŠ¤ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘... (1/4)")
        progress_bar.progress(25)
        
        if not os.path.exists("./base_model"):
            base_model_url = f"https://drive.google.com/uc?id={base_model_id}"
            gdown.download(base_model_url, "./my_base_model.tar.gz", quiet=False)
            
            # ì••ì¶• í•´ì œ
            with tarfile.open("./my_base_model.tar.gz", "r:gz") as tar:
                tar.extractall("./base_model/")
        
        # QLoRA ì–´ëŒ‘í„° ë‹¤ìš´ë¡œë“œ
        status_text.text("ğŸ”„ QLoRA ì–´ëŒ‘í„° ë‹¤ìš´ë¡œë“œ ì¤‘... (2/4)")
        progress_bar.progress(50)
        
        if not os.path.exists("./qlora_adapter"):
            qlora_url = f"https://drive.google.com/uc?id={qlora_adapter_id}"
            gdown.download(qlora_url, "./qlora_results.zip", quiet=False)
            
            # ì••ì¶• í•´ì œ
            with zipfile.ZipFile("./qlora_results.zip", 'r') as zip_ref:
                zip_ref.extractall("./qlora_adapter/")
        
        # í† í¬ë‚˜ì´ì € ë¡œë“œ
        status_text.text("ğŸ“ í† í¬ë‚˜ì´ì € ë¡œë“œ ì¤‘... (3/4)")
        progress_bar.progress(75)
        
        tokenizer = AutoTokenizer.from_pretrained("./base_model")
        
        # ëª¨ë¸ ë¡œë“œ ë° ì–´ëŒ‘í„° ì ìš©
        status_text.text("ğŸ§  AI ëª¨ë¸ ë¡œë“œ ì¤‘... (4/4)")
        progress_bar.progress(90)
        
        base_model = AutoModelForCausalLM.from_pretrained(
            "./base_model",
            torch_dtype=torch.float16,
            device_map="cpu",
            low_cpu_mem_usage=True
        )
        
        # QLoRA ì–´ëŒ‘í„° ì ìš©
        model = PeftModel.from_pretrained(base_model, "./qlora_adapter")
        
        progress_bar.progress(100)
        status_text.text("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        
        # UI ì •ë¦¬
        progress_bar.empty()
        status_text.empty()
        
        return model, tokenizer
        
    except Exception as e:
        st.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None

@st.cache_data
def load_data(db_name="financial_data.db", table_name="financial_data"):
    """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„° ë¡œë“œ"""
    try:
        conn = sqlite3.connect(db_name)
        df = pd.read_sql(f"SELECT * FROM {table_name}", conn)
        conn.close()
        return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

def generate_ai_response(model, tokenizer, question, company_data):
    """AI ëª¨ë¸ì„ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„±"""
    if model is None or tokenizer is None:
        return "AI ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    # íšŒì‚¬ ì •ë³´ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
    company_info = f"""
    ì¢…ëª©ëª…: {company_data['ì¢…ëª©ëª…']}
    í‹°ì»¤: {company_data['í‹°ì»¤']}
    í˜„ì¬ê°€: {company_data['í˜„ì¬ê°€']}
    PER: {company_data['PER_ìµœê·¼']}
    PBR: {company_data['PBR_ìµœê·¼']}
    ROE: {company_data['ROE_ìµœê·¼']}
    ë¶€ì±„ë¹„ìœ¨: {company_data['ë¶€ì±„ë¹„ìœ¨_ìµœê·¼']}
    """
    
    prompt = f"""ë‹¤ìŒì€ {company_data['ì¢…ëª©ëª…']}ì˜ ì¬ë¬´ ì •ë³´ì…ë‹ˆë‹¤:

{company_info}

ì§ˆë¬¸: {question}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì¸ ì¦ê¶Œ ë¶„ì„ê°€ ê´€ì ì—ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”:"""
    
    try:
        inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
        
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=300,
                temperature=0.7,
                top_p=0.9,
                do_sample=True,
                pad_token_id=tokenizer.pad_token_id
            )
        
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        # ì…ë ¥ í”„ë¡¬í”„íŠ¸ ì œê±°
        generated_text = response[len(prompt):].strip()
        
        return generated_text
        
    except Exception as e:
        return f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

def get_initial(korean_char):
    """í•œê¸€ ì´ˆì„± ì¶”ì¶œ"""
    ch_code = ord(korean_char) - ord('ê°€')
    if 0 <= ch_code < 11172:
        cho = ch_code // 588
        return ['ã„±','ã„²','ã„´','ã„·','ã„¸','ã„¹','ã…','ã…‚','ã…ƒ','ã……','ã…†','ã…‡','ã…ˆ','ã…‰','ã…Š','ã…‹','ã…Œ','ã…','ã…'][cho]
    return ""

# ë©”ì¸ ì•±
def main():
    # URL íŒŒë¼ë¯¸í„° ì½ê¸°
    url_params = st.experimental_get_query_params()
    
    # AI ëª¨ë¸ ë¡œë“œ
    if 'model_loaded' not in st.session_state:
        st.info("ğŸ¤– AI ëª¨ë¸ì„ ì²˜ìŒ ë¡œë“œí•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
        model, tokenizer = download_and_load_models()
        st.session_state.model = model
        st.session_state.tokenizer = tokenizer
        st.session_state.model_loaded = True
        
        if model is not None:
            st.success("âœ… AI ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! ì´ì œ ì§€ëŠ¥í˜• ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        st.rerun()
    
    # ë°ì´í„° ë¡œë“œ
    df = load_data()
    
    if df.empty:
        st.error("âŒ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì‚¬ì´ë“œë°” í•„í„°
    st.sidebar.header("ğŸ“‚ í•„í„° ì˜µì…˜")
    
    # URL íŒŒë¼ë¯¸í„°ì—ì„œ ê¸°ë³¸ê°’ ê°€ì ¸ì˜¤ê¸°
    default_initial = url_params.get("initial", ["ì „ì²´"])[0]
    default_search = url_params.get("search", [""])[0]
    default_company = url_params.get("company", [""])[0]
    
    # ì´ˆì„± í•„í„°
    initials = ['ì „ì²´', 'ã„±', 'ã„´', 'ã„·', 'ã„¹', 'ã…', 'ã…‚', 'ã……', 'ã…‡', 'ã…ˆ', 'ã…Š', 'ã…‹', 'ã…Œ', 'ã…', 'ã…']
    selected_initial = st.sidebar.selectbox("ğŸ”¡ ì¢…ëª©ëª… ì´ˆì„±:", initials, 
                                          index=initials.index(default_initial) if default_initial in initials else 0)
    
    # í…ìŠ¤íŠ¸ ê²€ìƒ‰
    search_term = st.sidebar.text_input("ğŸ” ì¢…ëª©ëª… ë˜ëŠ” í‹°ì»¤ ê²€ìƒ‰", value=default_search)
    
    # ê³ ê¸‰ ê²€ìƒ‰ ì˜µì…˜
    with st.sidebar.expander("ğŸ”§ ê³ ê¸‰ ê²€ìƒ‰ ì˜µì…˜"):
        # PER ë²”ìœ„ í•„í„°
        per_range = st.slider("PER ë²”ìœ„", 0.0, 50.0, (0.0, 50.0))
        
        # PBR ë²”ìœ„ í•„í„°
        pbr_range = st.slider("PBR ë²”ìœ„", 0.0, 10.0, (0.0, 10.0))
        
        # ì‹œê°€ì´ì•¡ ë²”ìœ„ (í˜„ì¬ê°€ ê¸°ì¤€)
        price_range = st.slider("ì£¼ê°€ ë²”ìœ„", 
                               int(df["í˜„ì¬ê°€"].min()), 
                               int(df["í˜„ì¬ê°€"].max()), 
                               (int(df["í˜„ì¬ê°€"].min()), int(df["í˜„ì¬ê°€"].max())))
    
    # ë°ì´í„° í•„í„°ë§
    filtered_df = df.copy()
    
    # ì´ˆì„± í•„í„° ì ìš©
    if selected_initial != "ì „ì²´":
        filtered_df = filtered_df[filtered_df["ì¢…ëª©ëª…"].apply(lambda x: get_initial(x[0]) == selected_initial)]
    
    # í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì ìš©
    if search_term:
        mask1 = filtered_df["ì¢…ëª©ëª…"].str.contains(search_term, case=False, na=False)
        mask2 = filtered_df["í‹°ì»¤"].str.contains(search_term, case=False, na=False)
        filtered_df = filtered_df[mask1 | mask2]
    
    # ê³ ê¸‰ í•„í„° ì ìš©
    filtered_df = filtered_df[
        (filtered_df["PER_ìµœê·¼"].between(per_range[0], per_range[1])) &
        (filtered_df["PBR_ìµœê·¼"].between(pbr_range[0], pbr_range[1])) &
        (filtered_df["í˜„ì¬ê°€"].between(price_range[0], price_range[1]))
    ]
    
    ì¢…ëª©_list = filtered_df["ì¢…ëª©ëª…"].tolist()
    
    if not ì¢…ëª©_list:
        st.warning("âŒ ì¡°ê±´ì— ë§ëŠ” ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì¢…ëª© ì„ íƒ
    if default_company and default_company in ì¢…ëª©_list:
        default_index = ì¢…ëª©_list.index(default_company)
    else:
        default_index = 0
    
    ì„ íƒí•œ_ì¢…ëª© = st.sidebar.selectbox("ğŸ“Œ ì¢…ëª© ì„ íƒ:", ì¢…ëª©_list, index=default_index)
    ì¢…ëª©_df = filtered_df[filtered_df["ì¢…ëª©ëª…"] == ì„ íƒí•œ_ì¢…ëª©].iloc[0]
    
    # URL ê³µìœ  ë§í¬ ìƒì„±
    share_url = f"?initial={selected_initial}&search={search_term}&company={ì„ íƒí•œ_ì¢…ëª©}"
    st.sidebar.markdown(f"ğŸ”— [ì´ ë¶„ì„ ê³µìœ í•˜ê¸°]({share_url})")
    
    # ----------------------- ë©”ì¸ ì»¨í…ì¸  -----------------------
    st.title(f"ğŸ“Š {ì„ íƒí•œ_ì¢…ëª©} ({ì¢…ëª©_df['í‹°ì»¤']}) AI ë¦¬ì„œì¹˜ ë¶„ì„")
    
    # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
    if len(ì¢…ëª©_list) < len(df):
        st.info(f"ğŸ” ê²€ìƒ‰ ê²°ê³¼: {len(ì¢…ëª©_list)}ê°œ ì¢…ëª© (ì „ì²´ {len(df)}ê°œ ì¤‘)")
    
    # ì¬ë¬´ ì§€í‘œ
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("í˜„ì¬ê°€", f"{ì¢…ëª©_df['í˜„ì¬ê°€']:,}ì›")
        st.metric("ROE (ìµœê·¼)", f"{ì¢…ëª©_df['ROE_ìµœê·¼']:.2f}%")
        st.metric("PER (ìµœê·¼)", f"{ì¢…ëª©_df['PER_ìµœê·¼']:.2f}")
        st.metric("PBR (ìµœê·¼)", f"{ì¢…ëª©_df['PBR_ìµœê·¼']:.2f}")
        st.metric("ë¶€ì±„ë¹„ìœ¨", f"{ì¢…ëª©_df['ë¶€ì±„ë¹„ìœ¨_ìµœê·¼']:.2f}%")
    
    with col2:
        st.metric("ìœ ë³´ìœ¨", f"{ì¢…ëª©_df['ìœ ë³´ìœ¨_ìµœê·¼']:.2f}%")
        st.metric("ë§¤ì¶œì•¡", f"{ì¢…ëª©_df['ë§¤ì¶œì•¡_ìµœê·¼']:,}ì›")
        st.metric("ì˜ì—…ì´ìµ", f"{ì¢…ëª©_df['ì˜ì—…ì´ìµ_ìµœê·¼']:,}ì›")
        st.metric("ìˆœì´ìµ", f"{ì¢…ëª©_df['ìˆœì´ìµ_ìµœê·¼']:,}ì›")
    
    # ì£¼ê°€ ì°¨íŠ¸
    st.markdown("### ğŸ“ˆ ì£¼ê°€ ì¶”ì´")
    price_cols = [col for col in df.columns if col.isdigit() and len(col) == 8]
    if price_cols:
        price_series = ì¢…ëª©_df[price_cols].astype(float)
        price_series.index = pd.to_datetime(price_cols, format='%Y%m%d')
        chart_df = price_series.reset_index().rename(columns={'index': 'ë‚ ì§œ'})
        st.line_chart(chart_df.set_index("ë‚ ì§œ"))
    
    # ë‰´ìŠ¤ ì„¹ì…˜
    st.markdown("### ğŸ“° ìµœê·¼ ë‰´ìŠ¤")
    if isinstance(ì¢…ëª©_df["ìµœì‹ ë‰´ìŠ¤"], str) and ì¢…ëª©_df["ìµœì‹ ë‰´ìŠ¤"].strip():
        for i, link in enumerate(ì¢…ëª©_df["ìµœì‹ ë‰´ìŠ¤"].splitlines(), 1):
            if link.strip():
                st.markdown(f"{i}. [ë‰´ìŠ¤ ë§í¬]({link.strip()})")
    else:
        st.info("ìµœê·¼ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # AI ë¶„ì„ ì„¹ì…˜
    st.markdown("### ğŸ¤– AI ì¦ê¶Œ ë¶„ì„")
    
    # ë¯¸ë¦¬ ì •ì˜ëœ ì§ˆë¬¸ë“¤
    preset_questions = [
        "ì´ ì¢…ëª©ì˜ íˆ¬ì ë§¤ë ¥ë„ëŠ” ì–´ë–¤ê°€ìš”?",
        "PERê³¼ PBR ì§€í‘œë¥¼ ì–´ë–»ê²Œ í•´ì„í•´ì•¼ í•˜ë‚˜ìš”?",
        "í˜„ì¬ ì¬ë¬´ ìƒíƒœì˜ ê°•ì ê³¼ ì•½ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ì´ ì¢…ëª©ì˜ ë¦¬ìŠ¤í¬ ìš”ì¸ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ë™ì¢… ì—…ê³„ ëŒ€ë¹„ ê²½ìŸë ¥ì€ ì–´ë–¤ê°€ìš”?"
    ]
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        user_question = st.text_input("ğŸ’¬ ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•˜ì„¸ìš”:", 
                                    placeholder="ì˜ˆ: ì´ ì¢…ëª©ì˜ PERì´ ë†’ìœ¼ë©´ ì–´ë–¤ í•´ì„ì´ ê°€ëŠ¥í•´?")
    
    with col2:
        selected_preset = st.selectbox("ğŸ“‹ ë¯¸ë¦¬ ì •ì˜ëœ ì§ˆë¬¸:", ["ì§ì ‘ ì…ë ¥"] + preset_questions)
    
    if selected_preset != "ì§ì ‘ ì…ë ¥":
        user_question = selected_preset
    
    if user_question and st.button("ğŸ” AI ë¶„ì„ ìš”ì²­", type="primary"):
        if st.session_state.get('model') is not None:
            with st.spinner("ğŸ¤– AIê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                ai_response = generate_ai_response(
                    st.session_state.model, 
                    st.session_state.tokenizer, 
                    user_question, 
                    ì¢…ëª©_df
                )
            
            st.markdown("#### ğŸ¯ AI ë¶„ì„ ê²°ê³¼")
            st.markdown(ai_response)
            
            # ë¶„ì„ ê²°ê³¼ ì €ì¥ ì˜µì…˜
            if st.button("ğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥"):
                analysis_text = f"""
# {ì„ íƒí•œ_ì¢…ëª©} AI ë¶„ì„ ê²°ê³¼

**ì§ˆë¬¸:** {user_question}

**AI ë¶„ì„:**
{ai_response}

**ê¸°ë³¸ ì •ë³´:**
- ì¢…ëª©ëª…: {ì¢…ëª©_df['ì¢…ëª©ëª…']}
- í‹°ì»¤: {ì¢…ëª©_df['í‹°ì»¤']}
- í˜„ì¬ê°€: {ì¢…ëª©_df['í˜„ì¬ê°€']:,}ì›
- PER: {ì¢…ëª©_df['PER_ìµœê·¼']:.2f}
- PBR: {ì¢…ëª©_df['PBR_ìµœê·¼']:.2f}
- ROE: {ì¢…ëª©_df['ROE_ìµœê·¼']:.2f}%
"""
                st.download_button(
                    label="ğŸ“¥ ë¶„ì„ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                    data=analysis_text,
                    file_name=f"{ì„ íƒí•œ_ì¢…ëª©}_AIë¶„ì„_{pd.Timestamp.now().strftime('%Y%m%d_%H%M')}.md",
                    mime="text/markdown"
                )
        else:
            st.error("âŒ AI ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•´ì£¼ì„¸ìš”.")
    
    # ê²€ìƒ‰ í†µê³„
    with st.expander("ğŸ“Š ê²€ìƒ‰ í†µê³„"):
        st.write(f"**ì „ì²´ ì¢…ëª© ìˆ˜:** {len(df)}")
        st.write(f"**í•„í„°ë§ëœ ì¢…ëª© ìˆ˜:** {len(filtered_df)}")
        st.write(f"**í‰ê·  PER:** {filtered_df['PER_ìµœê·¼'].mean():.2f}")
        st.write(f"**í‰ê·  PBR:** {filtered_df['PBR_ìµœê·¼'].mean():.2f}")
        st.write(f"**í‰ê·  ROE:** {filtered_df['ROE_ìµœê·¼'].mean():.2f}%")

if __name__ == "__main__":
    main()
